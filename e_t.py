# -*- coding: utf-8 -*-
"""E.T.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14HR0Y-MHjj5EBFJtsGD0xuAoUPvfiFcR

#üëΩ **Bienvenue sur E.T ! üëΩ**

> Vous √™tes sur l'outil E.T qui vous permet d'analyser toutes vos URL.üë®üèΩ‚Äçüíª


*R√©alis√© par [Tidiane Hubert](https://www.linkedin.com/in/tidianehubert/)*

‚ö†Ô∏è Avant de vous lancer dans l'outil, il faut dabord suivre plusieurs r√®gles pour que l'outil fonctionne correctement ‚ö†Ô∏è

1. Il vous faut un fichier **Excel** pour utiliser cette outil
2. Votre fichier doit contenir **2 colonnes** uniquement **[id, url]**

‚û°Ô∏è Le **principe de l'outil est simple** : E.T vous permet d'analyser l'accessibilit√©s de vos URLs et de ressortir les URLs qui sont vides.

‚û°Ô∏è Si jamais vous souhaitez analyser vos url images, c'est possible √©galement. Vous pourrez r√©cup√©rer les dimensions de celles-ci.üî•
"""

#@title Initialisation
#@markdown Vous n'avez rien √† faire, juste lancer la cellule pour que le bot s'initialise üöÄ


!pip install requests-futures &> /dev/null
import pandas as pd
import requests
import numpy as np
from google.colab import files
import tqdm as tdqm_module
import time as time_module
from requests_futures.sessions import FuturesSession
import csv
from PIL import Image
from io import BytesIO
import time
start_time = time.time()



print("Il faut que ton fichier ait 2 colonnes. Une avec les ID et une autre avec les urls :")
uploaded = files.upload()
start_time = time.time()


print("")
print("C'est parti, prochaine cellule üëá")

#@title üõ† Param√®trage üõ†
# @markdown *Si votre fichier est r√©pond aux normes attendus par l'outil alors vous aurez les donn√©es sur vos URLS.*

# @markdown ***C'est GRATUIT et made in Feedastic !***

chemin = list(uploaded.keys())[0]
df = pd.read_excel(chemin)
df_clean = []
nb_none = 0

colonne = df.iloc[:, 1]

for i in colonne:
  if pd.isnull(i) or not str(i).startswith("http"):
    nb_none = nb_none + 1

for image in colonne:
  if not pd.isnull(image) and str(image).startswith("http"):
    df_clean.append(image)

df = pd.DataFrame(df_clean)

code_200 = 0
code_301 = 0
code_302 = 0
code_404 = 0
code_401 = 0
code_402 = 0
code_403 = 0
code_500 = 0
code_502 = 0
code_503 = 0
code_504 = 0


session = FuturesSession()
futures = []
for image in df[0]:
  future = session.get(image)
  futures.append(future)


image_data = []
for future in tdqm_module.tqdm(futures):
  r = future.result()
  df_code = r.status_code
  if df_code == 200:
    code_200 += 1

  try:
    if 'image' in r.headers['content-type']:
      img = Image.open(BytesIO(r.content))
      width, height = img.size
      image_size_Mo = round(len(r.content) / (1024 * 1024), 2) # conversion en Mo et arrondi √† 2 d√©cimales
      image_data.append({'url': r.url, 'width': width, 'height': height,'size_en_Mo': image_size_Mo, 'status_code': df_code})
    else:
      image_data.append({'url': r.url, 'status_code': df_code})
  except Exception as e:
    if 'image' in r.headers['content-type']:
     print(f"Erreur lors de la lecture de l'image : {e}")


#Ajouter +1 dans le code erreur correspondant

  if df_code == 301:
    code_301 += 1

  if df_code == 302:
    code_302 += 1

  if df_code == 401:
    code_401 += 1

  if df_code == 402:
    code_402 += 1

  if df_code == 403:
    code_403 +=1

  if df_code == 404:
    code_404 += 1

  if df_code == 500:
    code_500 += 1

  if df_code == 502:
    code_502 += 1

  if df_code == 503:
    code_503 += 1

  if df_code == 504:
    code_504 += 1


print("")
print(f'Il y a {nb_none} produits qui ont des URLs vides')
print("")
print(f"- Code 200 : {code_200}")
print(f"- Code 301 : {code_301}")
print(f"- Code 302 : {code_302}")
print(f"- Code 401 : {code_401}")
print(f"- Code 402 : {code_402}")
print(f"- Code 403 : {code_403}")
print(f"- Code 404 : {code_404}")
print(f"- Code 500 : {code_500}")
print(f"- Code 502 : {code_502}")
print(f"- Code 503 : {code_503}")
print(f"- Code 504 : {code_504}")


df_image_data = pd.DataFrame(image_data)
df_image_data.to_excel('df_excel.xlsx', index=False)
print("")

print("Le fichier d'export peut mettre quelques minutes avant de se g√©n√©rer")

#@title ‚öôÔ∏è Quelques donn√©es importantes ‚öôÔ∏è
# @markdown *Si vous souhaitez avoir un r√©capitulatif des donn√©es que E.T peut vous sortir alors lancer cette partie.*

# @markdown üö® Attention : si la moyenne et la m√©diane pour le poid de vos images √©gale √† 0, alors c'est que vos images ont sont l√©g√®re. C'est une bonne chose.

# @markdown ***Et c'est toujours GRATUIT et made in Feedastic !***

#Dimensions attedues par les marketplaces
marketplaces_width = 3000
marketplaces_height = 3000

#Dimensions attedues par Google Ads
googleads_width = 250
googleads_height = 250

#Moyenne et m√©diane du poid des images
moyenne_image_poids = 0
mediane_image_poids = 0

#Moyenne et m√©diane du poid des images attendus des plateformes
marketplaces_poids_images = 5
googleads_poids_images = 16

#Afficher la moyenne des dimensions des images
if len(image_data) > 0:
  widths = df_image_data['width']
  heights = df_image_data['height']
  avg_width = round(sum(widths) / len(widths),2)
  avg_height = round(sum(heights) / len(heights),2)
  print(f"La moyenne des dimensions des images est de {avg_width} x {avg_height}.")
else:
  print("Il n'y a pas assez d'images pour calculer la moyenne.")


#Afficher la r√©partition en % des code erreurs
total_images = code_200 + code_301 + code_302 + code_401 + code_402 + code_403 + code_404 + code_500 + code_502 + code_503 + code_504

if total_images > 0:
  print("")
  print("R√©partition des codes erreurs en pourcentage :")
  print("")
  print(f"- Code 200 : {round(code_200 / total_images * 100, 2)}%")
  print(f"- Code 301 : {round(code_301 / total_images * 100, 2)}%")
  print(f"- Code 302 : {round(code_302 / total_images * 100, 2)}%")
  print(f"- Code 401 : {round(code_401 / total_images * 100, 2)}%")
  print(f"- Code 402 : {round(code_402 / total_images * 100, 2)}%")
  print(f"- Code 403 : {round(code_403 / total_images * 100, 2)}%")
  print(f"- Code 404 : {round(code_404 / total_images * 100, 2)}%")
  print(f"- Code 500 : {round(code_500 / total_images * 100, 2)}%")
  print(f"- Code 502 : {round(code_502 / total_images * 100, 2)}%")
  print(f"- Code 503 : {round(code_503 / total_images * 100, 2)}%")
  print(f"- Code 504 : {round(code_504 / total_images * 100, 2)}%")
else:
  print("Il n'y a pas assez d'images pour afficher la r√©partition des codes erreurs en pourcentage.")


#Moyenne du poid des images
df_image_data['size_Mo'] = df_image_data['size_en_Mo'] / 1024 / 1024
average_size_Mo = df_image_data['size_Mo'].mean()
print(f"La moyenne des poids d'images est de : {average_size_Mo:.2f} Mo")

#M√©diane du poid des images
median_size_Mo = df_image_data['size_Mo'].median()
print(f"La m√©diane des poids d'images est de : {median_size_Mo:.2f} Mo")

# Compter le nombre d'URLs dont la taille est sup√©rieure √† 5 Mo
count_large_images = 0
for index, row in df_image_data.iterrows():
    if row['size_Mo'] > 5:
        count_large_images += 1

print(f"Il y a {count_large_images} images dont la taille est sup√©rieure √† 5 Mo.")

#Pour les marketplaces
marketplace_width_score = avg_width * 100 / marketplaces_width
marketplace_height_score = avg_height * 100 / marketplaces_height

#Pour Google Ads
googleads_width_score = avg_width * 100 / googleads_width
googleads_height_score = avg_height * 100 / googleads_height

print("")
print(f"Les dimensions des images ont atteint {marketplace_width_score:.2f}% et {marketplace_height_score:.2f}% des dimensions recommand√©es par les marketplaces (soit {marketplaces_width} x {marketplaces_height}).")
print(f"Les dimensions des images ont atteint {googleads_width_score:.2f}% et {googleads_height_score:.2f}% des dimensions recommand√©es pour Google Ads (soit {googleads_width} x {googleads_height}).")

"""# Merci d'avoir utilis√© E.T üëΩ

√Ä la fin **E.T** vous offre un fichier Excel avec les url plusieurs donn√©es importantes s'il s'agit d'une image. Vous aurez √† votre disposition **(la taille et le code erreur de l'image) **

‚û°Ô∏è Si tu souhaites r√©cup√©rer ton fichier Excel, il te suffit d'aller sur le dossier en **haut √† gauche** et s√©lectionner le fichier **df_excel.xlsx**. Ensuite **"T√©l√©charger"**.


*   **200** : succ√®s de la requ√™te
*   **301** et **302** : redirection, respectivement permanente et temporaire
* **401** : utilisateur non authentifi√©
* **402**: utilisateur non authentifi√© ;
***403** : acc√®s refus√© ;
***404** : ressource non trouv√©e ;
***500**, **502** et **503** : erreurs serveur ;
***504** : le serveur n'a pas r√©pondu.
"""